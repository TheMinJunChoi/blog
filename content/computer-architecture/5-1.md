---
title: Cache overview
date: 2022.11.10
slug: 5-1
category: "5. Memory Hierarchy"
---


## Memory hierarchy
### Locality
- **Temporal locality**
    - Items accessed recently are likely to be accessed again soon
- **Spatial locality**
    - Items near those accessed recently are likely to be accessed soon
<br>

## Memory structure
- **SRAM** (cache memory attached to CPU)
    - Fastest (o.5ns ~ 2.5ns)
    - most expensive 
    - smallest
- **DRAM** (main memory)
    - Faster (50ns ~ 70ns)
    - more expensive
    - smaller
- **Disk** (HDD, SSD)
    - Slowest (5ms ~ 20ms)
    - cheapest
    - largest
<br>

### Use hierarchy
- Copy recently accessed (and nearby) items from disk to smaller DRAM memory
- Copy more recently accessed (and nearby) items from DRAM to smaller SRAM memory
<br>

### Term
- **Block**
    - The minimum unit of information
    - It can be either present or not present in a cache
- **Hit**
    - Accessed data is present
    - Hit ratio: # of hits / # of accesses
- **Miss** 
    - Accessed data is absent
    - Block is copied from lower level (Additional time taken)
    - Miss ratio: # of misses / # of access (= 1 - hit ratio)
<br>

## Direct mapped cache
Each memory location can be mapped directly to exactly one location in the cache

<center>
    <img src="/computer-architecture/5-1/01.jpg"  width="600">
</center>

- Cache address = (Block address) modulo (# of blocks in cache)
- Num of blocks in cache is power of 2 (e.g., 2, 4, 8, 16, 32, ...)
- The cache address is determined by the low-order bits of block address
- Tags contain the address information of the data (the high-order bits of the address)
- To avoid using meaningless information, add a valid bit for each cache block
    - Valid bit = 1 (the cache block contains valid information)
    - Valid bit = 0 (the cache block contains invalid information)
    - Initially, the valid bits of all cache blocks are set to 0
<br>

### Cache address
- 32-bit addresses
- num of cache blocks: $2^n$ blocks (the lowest n bits of the block address are used for the index)
- Block size: $2^m$ words ($2^{m+2}$ bytes)
    - m bits are used for the word within the block, 2 bits are used for the byte within the word
<center>
    <img src="/computer-architecture/5-1/02.jpg"  width="700">
</center>
<br>

### Cache size
<center>
    <img src="/computer-architecture/5-1/03.jpg"  width="600">
</center>

**Cache size** <br>
= Cache table size <br>
= Num of cache block $\times$ (valid bit length + tag length + block size(data length))

### Practice 1
- 32-bit addresses
- Num of cache blocks: $2^{10}$ blocks
- Block size: $2^0$ words ($2^2$ bytes)

**Cache size**<br>
= $2^{10} \times (1 + (32 - (10 + 0 + 2)) + 32)$ <br>
= $2^{10} \times 53$ bits
<br><br>

### Practice 2
- 32-bit addresses
- Num of cache blocks: 64 blocks
- Block size: 4 words 

**Cache size**<br>
= $2^{6} \times (1 + (32 - (6 + 2 + 2)) + 128)$ <br>
= $2^{6} \times 151$ bits
<br>

## More about
- If we increase the size of blocks, this may help reduce miss rate due to spatial locality 
- But, Larger blocks -> a smaller number of cache blocks -> more competition -> increased miss rate
- Increased miss penalty (the time for copying from lower level)
<br>

## Handling cache misses
On cache hit, CPU proceeds normally. But, on cache miss, the control unit of the CPU

**Soon will be updated!**